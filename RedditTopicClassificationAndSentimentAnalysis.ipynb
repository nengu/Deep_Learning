{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Topic Classification and Sentiment Analysis with NLP and Neural Nets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "Extracting social media comments characteristics and classifying them into correct threads or creating new group is always interesting and challenge topic. Reddit.com is one of the most popular social media sites, it has large user base, high post, comments QPS per day. \n",
    "While some of the posts fit into corresponding topics correctly, some others diverged from the initial topic. We would like to first use traditional Natural Language Processing approach to experiment topic modeling on posts and then dive deeper by looking into comments of each thread. There is a comment thread assigned for each post. “Karma” is net score determined by users’ voting up and down on each comment. These comments are valuable resource to explore Reddit World.\n",
    "\n",
    "This project will start off by using Latent Dirichlet Analysis together with TF-IDF to get a general view of reddit comment data set, then use Recursive Neural Networks to look into Reddit communities by sentiment analysis of Reddit comments.\n",
    "\n",
    "\n",
    "Below is code snippet for Reddit Ranking Algorithm\n",
    "<img src=http://image.beekka.com/blog/201203/bg2012030702.png>\n",
    "Please visit http://pastebin.com/bygavdb7 if you are interested in finding more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data \n",
    "Reddit comment dataset (publicly available comment) is ~1.7 billion JSON objects complete with the comment, score, author, subreddit, position in comment tree and other fields that are available through Reddit's API. This data set is perfect for doing NLP analysis at a large scale. We are only going to experiment on a smaller subset in this project.\n",
    "\n",
    "Reddit API regulations fro scraping:\n",
    "https://www.reddit.com/wiki/api\n",
    "\n",
    "The database has one table, May 2015, with the following fields:\n",
    "- created_utc\n",
    "- ups\n",
    "- subreddit_id\n",
    "- link_id\n",
    "- name\n",
    "- score_hidden\n",
    "- author_flair_css_class\n",
    "- author_flair_text\n",
    "- subreddit\n",
    "- id\n",
    "- removal_reason\n",
    "- gilded\n",
    "- downs\n",
    "- archived\n",
    "- author\n",
    "- score\n",
    "- retrieved_on\n",
    "- body\n",
    "- distinguished\n",
    "- edited\n",
    "- controversiality\n",
    "- parent_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "The main issue is that not all comments are context driven. There is a great number of  posts only contains a url for gif, photo albums or videos as react to certain post / comments.These comments provides very limited context information for sentiment analysis and thus should be removed from pre-processing step. We will also apply regex for removing outlier comments and inappropriate ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan and Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Traditional NLP Approach for Topic Modeling\n",
    "\t\t\t\t\t\n",
    "There are variety of methods for ‘understanding’ large corpuses of text. The most popular technique for topic modeling is known as Latent Dirichlet Allocation (LDA) is useful in many applications in other fields as well. In general, this topic model infers a set of topics from a corpus and assigns each document a level of participation in each topic. Term Frequency part of TF-IDF is bag of word assumption. LDA is similar to matrix factorization, it takes term document matrix and gives two matrices topic by word and document by topic matrix. It is assumed all words are equally important for calculating the conditional probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Neural Net for Discover Sentiment Analysis\n",
    "\n",
    "Neural network models are currently better at capturing sentiments of the comments.\n",
    "We will determining sentiment by the subreddit’s context through the positive and negative Karma labels using RNNs. Aside from recurrent structure that brings weights from previous states, RNN also has gating feature. Gating takes the output of any time step and the next input, and performs a transformation before feeding the result back into the RNN. There are several types of gates, the LSTM being the most popular. Other approaches to address this problem include gradient clipping, steeper gates, and better optimizers. Labeling positive/negative for the full comment is better with long-term dependencies for enricher context. Gated Recurrent Unit and Long-Short Term Memory are models that accounts for these problems and are best suited for labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "To be continued ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "1. CS224D slides\n",
    "2. Deep Learning.tv\n",
    "3. Spark LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
